# Spark 2.4.0编程指南--spark sql入门

## 更多资源
- github: https://github.com/opensourceteams/spark-scala-maven-2.4.0

## 文档
- (官网文档): http://spark.apache.org/docs/2.4.0/sql-getting-started.html

## 前置条件
- 已安装好java(选用的是java 1.8.0_191)
- 已安装好scala(选用的是scala  2.11.121)
- 已安装好hadoop(选用的是Hadoop 3.1.1)
- 已安装好spark(选用的是spark 2.4.0)

## 技能标签
- Spark 2.4.0 Spark session available as 'spark'
- 在Spark 2.0之后，RDD被数据集(Dataset)取代 
- Spark session 读取HDFS文件做为数据集
- 数据集函数，count(),first(),filter(),reduce()
- 统计所有行单词总个数
- 计算行中最多单词的个数
- 计算最多单词个数的行
- 按单词分组统计个数(WordCount)
- 官网: http://spark.apache.org/docs/2.4.0/quick-start.html


